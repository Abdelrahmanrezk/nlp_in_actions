{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jeferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'at',\n",
       " '26.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Thomas Jeferson began building Monticello at the age at 26.\"\"\"\n",
    "\n",
    "sentence.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note !\n",
    "The split method is the built-in method for string objects and as we can see it has \"26.\" which we can imagine its float number from 26.0. So in like these cases, we may remove punctuation to have a string of \"26\" that represents for any form like \"26?\" \"26.\" \"26!\" and other forms.\n",
    "\n",
    "But for now lets handle like these cases later.\n",
    "\n",
    "We can now get a vector from these words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot-Encoding\n",
    "\n",
    "This sequence of one-hot vectors captures the original tokens orders of the text, and for this sequence captures it used with some of the Sequence-to-Sequence deep learning models, because it retains all the meaning inherent in the original text.\n",
    "\n",
    "- Split\n",
    "- Get unique words and sort lexographically\n",
    "- 2d-metrix, each column represent the words order in the orignal codument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jeferson', 'began', 'building', 'Monticello', 'at', 'the', 'age', 'at', '26.']\n",
      "==================================================\n",
      "['26.', 'Jeferson', 'Monticello', 'Thomas', 'age', 'at', 'began', 'building', 'the']\n",
      "==================================================\n",
      "(10, 9)\n"
     ]
    }
   ],
   "source": [
    "# Split first\n",
    "tokens = sentence.split()\n",
    "print(tokens)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Build the vocab from unique words\n",
    "vocab = sorted(set(tokens))\n",
    "print(vocab)\n",
    "print(\"=\"*50)\n",
    "\n",
    "one_hot = np.zeros((len(tokens), len(vocab)), int)\n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas Jeferson began building Monticello at the age at 26.\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, word in enumerate(tokens):\n",
    "    one_hot[i, vocab.index(word)] = 1 \n",
    "\n",
    "    \n",
    "# Now the sentence \n",
    "print(sentence)\n",
    "print(\"=\"* 50)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note !!\n",
    "\n",
    "We can see that first column has 1 in the last row as \"26.\" came the last word and second columns have 1 in the second row as Jefferson came to the second word in the original document, so the sequence of a word appearing in the document has capture using the one-hot encoding, but what about 100 words? about all the words of some language? \n",
    "\n",
    "For now, let's convert what we mentioned by word as a column and represent the word in the columns that correspond to it and index the row for much knowledge capture instead of just 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26.</th>\n",
       "      <th>Jeferson</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>Thomas</th>\n",
       "      <th>age</th>\n",
       "      <th>at</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   26.  Jeferson  Monticello  Thomas  age  at  began  building  the\n",
       "0    0         0           0       1    0   0      0         0    0\n",
       "1    0         1           0       0    0   0      0         0    0\n",
       "2    0         0           0       0    0   0      1         0    0\n",
       "3    0         0           0       0    0   0      0         1    0\n",
       "4    0         0           1       0    0   0      0         0    0\n",
       "5    0         0           0       0    0   1      0         0    0\n",
       "6    0         0           0       0    0   0      0         0    1\n",
       "7    0         0           0       0    1   0      0         0    0\n",
       "8    0         0           0       0    0   1      0         0    0\n",
       "9    1         0           0       0    0   0      0         0    0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(one_hot, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So 1 at first columns, as we mentioned, represent the position of the word in the original document and so on. But the vector of the word based on the index it appears in the orginal document with**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Frequency of words not their order\n",
    "\n",
    "Machine learning can get the pattern from the data even if you ignore the order of words that appeared in the document, check the sentence after you have **sort it**, it's like when you building sentence from some of the shuffled words when you in a new language you learn, this what we need here is to compress the whole matrix into just vector that belong as your unique words in the corps, and you can use just 10,000 most repeated ones, not just this we can split the document into a small sentence, which will contain just small number of words and for this, it's like rare words because the same word may be repeated more than ones in the document rather than in a sentence rather than in the phrase, and this gives the model to get intuition about the words of the sentence as rare words when you have the whole vector as zeros as all unique words except those ones of words comes in this sentence.\n",
    "\n",
    "So let's rebuild vector instead of 2d-matrix in one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Thomas': 1,\n",
       "         'Jeferson': 1,\n",
       "         'began': 1,\n",
       "         'building': 1,\n",
       "         'Monticello': 1,\n",
       "         'at': 1,\n",
       "         'the': 1,\n",
       "         'age': 1,\n",
       "         'of': 1,\n",
       "         '26.': 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Thomas Jeferson began building Monticello at the age of 26.\"\"\"\n",
    "\n",
    "vector = collections.Counter()\n",
    "\n",
    "unique_words = set(sorted(sentence.split())) \n",
    "\n",
    "for word in sentence.split():\n",
    "    vector[word] = 1\n",
    "    \n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More !\n",
    "\n",
    "its just one document and no words are repeated what we can do with more than one document, we can first build the **lexicon** the vocab that you have in the corps, then sort this bag-of-words, and for each document, dictionary give it the index of its appearing in your sorted bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>26.</th>\n",
       "      <th>Jeferson</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>Thomas</th>\n",
       "      <th>age</th>\n",
       "      <th>at</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      26.  Jeferson  Monticello  Thomas  age  at  began  building  of  the\n",
       "sent    1         1           1       1    1   1      1         1   1    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.Series(dict([(token, 1) for token in sorted(sentence.split())])), columns=['sent' ]).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thomas Jeferson began building Monticello at the age at 26.\\nConstruction was done mostly by local masons and carpenters.\\nHe moved into the South Pavilion in 1770.\\nTurning Monticello into a neoclassical masterpiece was Jefferson's obsession.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"\"\"Thomas Jeferson began building Monticello at the age at 26.\\n\"\"\"\n",
    "\n",
    "sentences += \"\"\"Construction was done mostly by local masons and carpenters.\\n\"\"\"\n",
    "\n",
    "sentences += \"\"\"He moved into the South Pavilion in 1770.\\n\"\"\"\n",
    "\n",
    "sentences += \"\"\"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"\"\"\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas Jeferson began building Monticello at the age at 26.',\n",
       " 'Construction was done mostly by local masons and carpenters.',\n",
       " 'He moved into the South Pavilion in 1770.',\n",
       " \"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corps = {}\n",
    "sentences_split = sentences.split('\\n')\n",
    "sentences_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jeferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>26.</th>\n",
       "      <th>Construction</th>\n",
       "      <th>...</th>\n",
       "      <th>South</th>\n",
       "      <th>Pavilion</th>\n",
       "      <th>in</th>\n",
       "      <th>1770.</th>\n",
       "      <th>Turning</th>\n",
       "      <th>a</th>\n",
       "      <th>neoclassical</th>\n",
       "      <th>masterpiece</th>\n",
       "      <th>Jefferson's</th>\n",
       "      <th>obsession.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent_1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Thomas  Jeferson  began  building  Monticello  at  the  age  26.  \\\n",
       "sent_1       1         1      1         1           1   1    1    1    1   \n",
       "sent_2       0         0      0         0           0   0    0    0    0   \n",
       "sent_3       0         0      0         0           0   0    1    0    0   \n",
       "sent_4       0         0      0         0           1   0    0    0    0   \n",
       "\n",
       "        Construction  ...  South  Pavilion  in  1770.  Turning  a  \\\n",
       "sent_1             0  ...      0         0   0      0        0  0   \n",
       "sent_2             1  ...      0         0   0      0        0  0   \n",
       "sent_3             0  ...      1         1   1      1        0  0   \n",
       "sent_4             0  ...      0         0   0      0        1  1   \n",
       "\n",
       "        neoclassical  masterpiece  Jefferson's  obsession.  \n",
       "sent_1             0            0            0           0  \n",
       "sent_2             0            0            0           0  \n",
       "sent_3             0            0            0           0  \n",
       "sent_4             1            1            1           1  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, sent in enumerate(sentences_split):\n",
    "    corps['sent_' + str(i+1)] = dict([(token, 1) for token in sent.split()])\n",
    "\n",
    "\n",
    "# data frame will build the columns from your unique words across all documents\n",
    "\n",
    "df = pd.DataFrame.from_records(corps).fillna(0).astype(int).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Product\n",
    "\n",
    "As we have this table we can see that some of the words overlap with the same words in other documents, and from this point, we can get the similarity between two documents as number of common words, and this can help us in searching for similar documents and other applications, all of this can be done using the dot products\n",
    "\n",
    "The dot product is like matrix multiplications, it outputs a scalar (single numbers) from multiplication 2-vectors together, multiply each number by corresponding one in the other vector then add them.\n",
    "\n",
    "Example:\n",
    "\n",
    "- 1* 2 + 2* 3 + 3* 4 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([2,3,4])\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thomas</th>\n",
       "      <th>Jeferson</th>\n",
       "      <th>began</th>\n",
       "      <th>building</th>\n",
       "      <th>Monticello</th>\n",
       "      <th>at</th>\n",
       "      <th>the</th>\n",
       "      <th>age</th>\n",
       "      <th>26.</th>\n",
       "      <th>Construction</th>\n",
       "      <th>...</th>\n",
       "      <th>South</th>\n",
       "      <th>Pavilion</th>\n",
       "      <th>in</th>\n",
       "      <th>1770.</th>\n",
       "      <th>Turning</th>\n",
       "      <th>a</th>\n",
       "      <th>neoclassical</th>\n",
       "      <th>masterpiece</th>\n",
       "      <th>Jefferson's</th>\n",
       "      <th>obsession.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent_1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Thomas  Jeferson  began  building  Monticello  at  the  age  26.  \\\n",
       "sent_1       1         1      1         1           1   1    1    1    1   \n",
       "sent_2       0         0      0         0           0   0    0    0    0   \n",
       "sent_3       0         0      0         0           0   0    1    0    0   \n",
       "sent_4       0         0      0         0           1   0    0    0    0   \n",
       "\n",
       "        Construction  ...  South  Pavilion  in  1770.  Turning  a  \\\n",
       "sent_1             0  ...      0         0   0      0        0  0   \n",
       "sent_2             1  ...      0         0   0      0        0  0   \n",
       "sent_3             0  ...      1         1   1      1        0  0   \n",
       "sent_4             0  ...      0         0   0      0        1  1   \n",
       "\n",
       "        neoclassical  masterpiece  Jefferson's  obsession.  \n",
       "sent_1             0            0            0           0  \n",
       "sent_2             0            0            0           0  \n",
       "sent_3             0            0            0           0  \n",
       "sent_4             1            1            1           1  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31,)\n",
      "(31,)\n",
      "(31,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "sent_1 = df.iloc[0]\n",
    "sent_2 = df.iloc[1]\n",
    "sent_3 = df.iloc[2]\n",
    "sent_4 = df.iloc[2]\n",
    "print(sent_1.shape)\n",
    "print(sent_2.shape)\n",
    "print(sent_3.shape)\n",
    "print(sent_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# As we can see how sent_1 is similar to other sentences\n",
    "print(sent_1.T.dot(sent_2))\n",
    "print(sent_1.T.dot(sent_3))\n",
    "print(sent_1.T.dot(sent_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VSM\n",
    "\n",
    "So we have now moved from just text to one-hot but it was a huge sparse 2d-matrix to represent just one document, instead, we have now the first **Vector Space Model**, which we can deal with and get similarities to add two vectors together and other math operations.\n",
    "\n",
    "This representation of binary vector has a lot of power for document retriver and for search for many years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Improvement\n",
    "\n",
    "NLP pipeline has a lot of stages involved in, so each of these stages can affect each other like in the tokenization we have made using a simple method associated with string **split** we have the word **26.** with this point and in other stages of the pipeline like **steaming** this will mislead the idea of group similar words together as it will be different from [26 or 26? or 26#] and others so the tokenizations process need to be more deeper than just spaces because some words can be separated using other punctuations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jeferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'at',\n",
       " '26',\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Thomas Jeferson began building Monticello at the age at 26.\"\"\"\n",
    "\n",
    "tokens = re.split(r'[-\\s.,;!?]+', sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints\n",
    "\n",
    "\n",
    "- [] means and char inside\n",
    "- \\s means spaces\n",
    "- .,;!? means any of these chars beside spaces above \n",
    "- **+** means any of these chars comes one or more should be split\n",
    "\n",
    "\n",
    "Other regular expression using NLTK:\n",
    "look at \\s and \\S "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " 'Jeferson',\n",
       " 'began',\n",
       " 'building',\n",
       " 'Monticello',\n",
       " 'at',\n",
       " 'the',\n",
       " 'age',\n",
       " 'at',\n",
       " '26',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Thomas Jeferson began building Monticello    at the age at 26.\"\"\"\n",
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
    "tokenizer.tokenize(sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thomas',\n",
       " ' ',\n",
       " 'Jeferson',\n",
       " ' ',\n",
       " 'began',\n",
       " ' ',\n",
       " 'building',\n",
       " ' ',\n",
       " 'Monticello',\n",
       " '    ',\n",
       " 'at',\n",
       " ' ',\n",
       " 'the',\n",
       " ' ',\n",
       " 'age',\n",
       " ' ',\n",
       " 'at',\n",
       " ' ',\n",
       " '26']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Thomas Jeferson began building Monticello    at the age at 26.\"\"\"\n",
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\s+')\n",
    "tokenizer.tokenize(sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreebankWordTokenizer\n",
    "\n",
    "TreebankWordTokenizer is a better word tokenizer from the nltk its combines a variety of common rules for English word tokenization for example its separate phrase-terminating punctuation (?!) from adjacent tokens and retains decimal numbers containing a period as a single token. As it contain a rules for English constructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monticello',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'designed',\n",
       " 'as',\n",
       " 'UNESCO',\n",
       " 'World',\n",
       " 'Heritage',\n",
       " 'Site',\n",
       " 'until',\n",
       " '1987',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"Monticello wasn't designed as UNESCO World Heritage Site until 1987.\"\"\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
